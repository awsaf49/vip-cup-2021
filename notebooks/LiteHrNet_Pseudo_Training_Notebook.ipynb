{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LiteHrNet  Pseudo Training Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y439R_c77rYI"
      },
      "source": [
        "# Set Variables for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLnaUGlkDX1_"
      },
      "source": [
        "!wget 'https://storage.googleapis.com/kaggle-data-sets/1360215/2429215/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210808%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210808T122320Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=95eb7522461a1e68faa579645cb304c52b09421fc17a4c1d9a26eaeb02d2473e87ca3c5e1eb5d467b1a6c10ca6224d727a398a5603a3a2dd8d53c96854b35e841801516ac34c9f0edf022e7289ba719940774414311b897342428d49753260be7f1e5df15222709bead811a7bf96610c7d7f07839b0c054ae4d71a9f877bc9b325ecfa368b878f950e3f2b58fd4c3f08ecbaa40d61ce513569bf6a42480c7190a4243d912e58f07e67d6dbd8f2b78d6b8a656adc1a43afc70769637f45eb6b419e90a6107ac95b32fc2ee9bb1c8217ba66cbbdfd67dc06351b81e8dfdae63a53f48fe82183d418da54f0b845e349d3d1759f31b7852b593481aafc387f431fe6' -O data.zip\n",
        "!mkdir -p /content/vipcup2021-dataset\n",
        "!unzip -q /content/data.zip -d /content/vipcup2021-dataset\n",
        "!rm -r /content/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04xRpj8o0pqB"
      },
      "source": [
        "vip_data_dir = \"/content/vipcup2021-dataset\"    # Make sure train, valid, test1 folders are immediately inside this directory\n",
        "vip_transformed_data_dir = \"/content/transformed\"   # Make sure train, valid, test1 folders of transformed data are immediately inside this directory\n",
        "work_dir = \"\"   # Make Sure this is a valid existing directory. Make a folder and set the path here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltwRowZa73fR"
      },
      "source": [
        "WIDTH = 384\n",
        "HEIGHT = 512\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9FpJLgR75An"
      },
      "source": [
        "# Variables for Pseudo Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbDlGmdycgd7"
      },
      "source": [
        "!pip install gdown\n",
        "!gdown --id 1N0Q9TOCdX-R4yI7kFhL0Dg39EytlP1QD\n",
        "!gdown --id 16XAo2mwUQrKo_D_-f3aYnxg5qioj6DUj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6suODR1974a-"
      },
      "source": [
        "weight_path = \"/content/liteHRNet.pth\"   # path link of a .pth file of LiteHrNet from where training should be re-loaded\n",
        "pseudo_df = \"/content/pseudo.csv\"  # path link of the dataframe containing the pseudo-label information of 2250 unlabelled train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDXbW6O8iM8"
      },
      "source": [
        "# Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9yG5If8hZ3"
      },
      "source": [
        "import shutil, os\n",
        "\n",
        "!mkdir personbbox\n",
        "%cd personbbox\n",
        "!gdown --id 1EVCVl9H0mjJyCrhLqvxaBHPB62-ev9U1 ## mmposeunlabelledpersonbbox\n",
        "mmposeunlabel_zip='/content/personbbox/mmposeunlabelledpersonbbox.zip'\n",
        "!unzip {mmposeunlabel_zip}\n",
        "!rm {mmposeunlabel_zip}\n",
        "shutil.copytree('/content/personbbox/mmposeunlabelledpersonbbox/yolo/yolov5/runs/detect/exp/labels', '/content/labels')\n",
        "%cd ..\n",
        "shutil.rmtree('/content/personbbox') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVE_LRyJDfGp"
      },
      "source": [
        "%%writefile generate_cover.py\n",
        "\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2,os\n",
        "from glob import glob\n",
        "import scipy.io as scio\n",
        "import scipy\n",
        "import shutil\n",
        "from matplotlib.colors import rgb2hex\n",
        "from skimage.morphology import reconstruction\n",
        "from skimage.morphology import disk\n",
        "from skimage.filters.rank import gradient\n",
        "import skimage\n",
        "from tqdm import tqdm\n",
        "os.system('pip install git+https://github.com/albumentations-team/albumentations')\n",
        "import albumentations as A\n",
        "\n",
        "kplines = [(0, 1), (1, 2), (12, 2), (12, 3), (3, 4), (4, 5), (6, 7),\n",
        "            (7, 8), (8, 12), (12, 9), (9, 10), (10, 11), (12, 13)]\n",
        "name2idx = {\n",
        "    \"Right ankle\":0,\n",
        "    \"Right knee\":1,\n",
        "    \"Right hip\":2,\n",
        "    \"Left hip\":3,\n",
        "    \"Left knee\":4,\n",
        "    \"Left ankle\":5,\n",
        "    \"Right wrist\":6,\n",
        "    \"Right elbow\":7,\n",
        "    \"Right shoulder\":8,\n",
        "    \"Left shoulder\":9,\n",
        "    \"Left elbow\":10,\n",
        "    \"Left wrist\":11,\n",
        "    \"Thorax\":12,\n",
        "    \"Head top\":13, \n",
        "}\n",
        "idx2name = {v:k for k,v in name2idx.items()}\n",
        "\n",
        "def load_kps(kp_path):\n",
        "    gt  = scio.loadmat(kp_path)['joints_gt']\n",
        "    kps = gt[:2].transpose(2, 1, 0) # => (num_image, num_limb, 2) => (None, 14, 2)\n",
        "    return kps.astype(int)\n",
        "\n",
        "def draw_kp(img, kps, kplines, line_th=1, circle_th=2, fontScale=1, text_th =2, text=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        img      : image (R, G, B)\n",
        "        kps      : keypoints (num_points, 2)\n",
        "        kplines  : limb line tuple index\n",
        "        text     : show text or not\n",
        "    Returns:\n",
        "        drew image\n",
        "    \"\"\"\n",
        "    cmap   = plt.get_cmap('rainbow')\n",
        "    colors = [cmap(i) for i in np.linspace(0, 1, len(kps) + 2)]\n",
        "    colors = [(c[2] * 255, c[1] * 255, c[0] * 255) for c in colors]\n",
        "    for idx, kpline in enumerate(kplines):\n",
        "        img = cv2.line(img.astype(float), tuple(kps[kpline[0]]), tuple(kps[kpline[1]]), thickness=line_th,\n",
        "                       color=colors[idx], lineType=cv2.LINE_AA)\n",
        "    for idx in range(len(kps)):\n",
        "        color = colors[idx]\n",
        "        img = cv2.circle(img.astype(float),tuple(kps[idx]), circle_th, color , cv2.FILLED)\n",
        "        if text:\n",
        "            w = img.shape[1]\n",
        "            px = kps[idx][0]\n",
        "            py = kps[idx][1]\n",
        "            if px>w//2:\n",
        "                px+=10\n",
        "                color = (255,0,0)\n",
        "            else:\n",
        "                px-=30\n",
        "                color = (0,0,255)\n",
        "            img = cv2.putText(img, str(idx), (px, py), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                               fontScale=fontScale, color=color, thickness=text_th, lineType=cv2.LINE_AA)\n",
        "    return img.astype('uint8')\n",
        "\n",
        "\n",
        "            \n",
        "def apply_selective_thorax(main_img,transformed_image,point):\n",
        "    extra=int(point)\n",
        "    new_img=main_img.copy()\n",
        "    new_img[extra:,:]=transformed_image[extra:,:]\n",
        "    return new_img\n",
        "\n",
        "def pad_across_width(image):\n",
        "    shapes=image.shape\n",
        "    h=shapes[0]\n",
        "    w=shapes[1]\n",
        "    if len(shapes)>2:\n",
        "        c=shapes[-1]\n",
        "\n",
        "    diff=h-w\n",
        "    side1=int(diff/2)\n",
        "    side2=diff-side1\n",
        "\n",
        "    s1=np.zeros((h,side1)).astype(image.dtype) if len(shapes)==2 else np.zeros((h,side1,c)).astype(image.dtype) \n",
        "    s2=np.zeros((h,side2)).astype(image.dtype) if len(shapes)==2 else np.zeros((h,side2,c)).astype(image.dtype) \n",
        "\n",
        "    new_image=image.copy()\n",
        "    new_image=np.concatenate([s1,new_image,s2],axis=1)\n",
        "    return new_image\n",
        "tpoint=name2idx[\"Thorax\"]\n",
        "\n",
        "def cover_gen(points,image,return_coord=False):\n",
        "    cover=np.zeros(image.shape,dtype=image.dtype)\n",
        "    \n",
        "    cover_corner_right=points[:,0].max()+20\n",
        "    cover_corner_left=points[:,0].min()-20\n",
        "    low=150\n",
        "    hthorax=points[tpoint][1]\n",
        "\n",
        "    if len(image.shape)>2:\n",
        "        cover[hthorax:low,cover_corner_left:cover_corner_right,0]=1# if image.dtype=='uint8' else 255.0\n",
        "        cover=cover[:,:,0]\n",
        "    else:\n",
        "        cover[hthorax:low,cover_corner_left:cover_corner_right]=1 #if image.dtype=='uint8' else 255.0\n",
        "    \n",
        "    if return_coord:\n",
        "        return ((cover_corner_left,hthorax),(cover_corner_right,low)),cover\n",
        "    return cover\n",
        "\n",
        "def combine(image,path1,path2):\n",
        "    albu=A.Compose([\n",
        "                   A.augmentations.domain_adaptation.HistogramMatching(path2,blend_ratio=(0.5, 0.9),p=1),\n",
        "    A.augmentations.domain_adaptation.FDA(path1,p=1,beta_limit=0.05)])\n",
        "    albu_im= albu(image=image)['image']\n",
        "    return albu_im\n",
        "\n",
        "def combiner(image1,image2,cover,final_channel=1):\n",
        "    if len(cover.shape)==2:\n",
        "        cover=np.expand_dims(cover,axis=-1)\n",
        "    if len(image2.shape)==2:\n",
        "        image2=np.expand_dims(image2,axis=-1)\n",
        "    \n",
        "    if len(image1.shape)>2&image1.shape[-1]!=1:\n",
        "        image1=np.expand_dims(image1[:,:,0],axis=-1)\n",
        "    \n",
        "    total=(1-cover)*image1+cover*image2\n",
        "    if final_channel==3:\n",
        "        return np.stack([total,total,total])\n",
        "    return total\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--data-dir', type=str, default='/kaggle/input/ieee-vip-cup-2021-train-val-dataset/', help='main directory of data')\n",
        "    parser.add_argument('--save-dir', type=str, default='/kaggle/working/VIP',help=\"where to save files, a new directory\")\n",
        "    opt = parser.parse_args()\n",
        "    \n",
        "    save_at=opt.save_dir#'/kaggle/working'\n",
        "    global_path=opt.data_dir\n",
        "    \n",
        "#     if os.path.exists(save_at):\n",
        "#         save_at=os.path.join(save_at,'VIP')\n",
        "        \n",
        "    print('Copying ...')\n",
        "    try:\n",
        "        shutil.copytree(global_path,save_at)\n",
        "    except:\n",
        "        shutil.rmtree(save_at)\n",
        "        shutil.copytree(global_path,save_at)\n",
        "    \n",
        "    print('Finding Train statistics...')\n",
        "    \n",
        "    uncover=[]\n",
        "    cover1=[]\n",
        "    cover2=[]\n",
        "    files_dir=os.path.join(global_path,'train')\n",
        "    if len(os.listdir(files_dir))<4:\n",
        "        files_dir=os.path.join(files_dir,'train')\n",
        "    files=os.listdir(files_dir)\n",
        "    uncover_images_list=[]\n",
        "    for f in files:\n",
        "        current_dir=os.path.join(files_dir,f,'IR')\n",
        "        if 'uncover' in os.listdir(current_dir):\n",
        "            uncover.append(f)\n",
        "            uncover_images_list.extend(glob(os.path.join(current_dir,'uncover/*')))\n",
        "\n",
        "        if 'cover1' in os.listdir(current_dir):\n",
        "            cover1.append(f)\n",
        "        if 'cover2' in os.listdir(current_dir):\n",
        "            cover2.append(f)\n",
        "\n",
        "    print(f'Uncover dirs : {len(uncover)}, Total files: {len(uncover_images_list)}')\n",
        "    print(f'Cover1 dirs : {len(cover1)}')\n",
        "    print(f'Cover2 dirs : {len(cover2)}')\n",
        "    \n",
        "    cover2_path=['image_000027.png',\n",
        "     'image_000041.png',\n",
        "     'image_000038.png',\n",
        "     'image_000023.png']\n",
        "    \n",
        "    cover2_path=[os.path.join(files_dir,'00062/IR/cover2',i) for i in cover2_path]\n",
        "    print('Selected cover images are : ',cover2_path)\n",
        "    \n",
        "    copy_dir=os.path.join(save_at,'train')\n",
        "    if len(os.listdir(copy_dir))<5:\n",
        "        copy_dir=os.path.join(copy_dir,'train')\n",
        "        \n",
        "    print('Generating cover images from uncover')   \n",
        "    for file_num in tqdm(sorted(uncover)):\n",
        "        image_dir=sorted(glob(os.path.join(copy_dir,file_num,'IR','uncover','*')))\n",
        "        keypoints_path=os.path.join(copy_dir,file_num,'joints_gt_IR.mat')\n",
        "\n",
        "        kp=load_kps(keypoints_path)\n",
        "        for i in range(len(image_dir)):\n",
        "            image_path=image_dir[i]\n",
        "\n",
        "            image=cv2.imread(image_path)\n",
        "            point=kp[i-1]\n",
        "            ((x1,y1),(x2,y2)),cover=cover_gen(point,image[:,:,0],return_coord=True)\n",
        "            final_im=combine(image,cover2_path,cover2_path)\n",
        "            final_im=combiner(image,final_im,cover)\n",
        "\n",
        "            cv2.imwrite(image_dir[i],final_im)\n",
        "    print('Completed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQnARZrnDkXs"
      },
      "source": [
        "!python generate_cover.py --data-dir $vip_data_dir --save-dir $vip_transformed_data_dir "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl_O8HCQ9kCP"
      },
      "source": [
        "!pip install -q imagesize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_waEtQ9j6s"
      },
      "source": [
        "%%writefile /content/test_coco.py\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as scio\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import os, shutil\n",
        "from glob import glob\n",
        "tqdm.pandas()\n",
        "import json\n",
        "import datetime\n",
        "import imagesize\n",
        "from sklearn.model_selection import GroupKFold \n",
        "import scipy.io as scio\n",
        "import cv2\n",
        "\n",
        "def load_kps(kp_path, width, height, new_width, new_height):\n",
        "    gt  = scio.loadmat(kp_path)['joints_gt'] # label = if_ocluded\n",
        "    kps = gt.transpose(2, 1, 0).astype(np.float64) # => (num_image, num_limb, 3) or (None, 14, 3)\n",
        "    kps[..., 0] = (kps[...,0]-1)/width*new_width    # converting one indexing to zero indexing\n",
        "    kps[..., 1] = (kps[...,1]-1)/height*new_height\n",
        "    kps[..., 2] = 2- kps[...,2] # coco format\n",
        "    return kps.astype(np.int32)\n",
        "\n",
        "def load_image(image_path):\n",
        "    return cv2.imread(image_path)[...,::-1]\n",
        "\n",
        "\n",
        "def read_resize(file_path, dim=128, width=128, height=128, aspect_ratio=True):\n",
        "    img = load_image(file_path)\n",
        "    h, w = img.shape[:2]  # orig hw\n",
        "    if aspect_ratio:\n",
        "        r = dim / max(h, w)  # resize image to img_size\n",
        "        interp = cv2.INTER_AREA if r < 1 else cv2.INTER_LINEAR\n",
        "        if r != 1:  # always resize down, only resize up if training with augmentation\n",
        "            img = cv2.resize(img, (int(w * r), int(h * r)), interpolation=interp)\n",
        "            new_h, new_w = img.shape[:2]\n",
        "    else:\n",
        "        img = cv2.resize(img, (width,height), cv2.INTER_AREA)\n",
        "        new_w = dim; new_h = dim\n",
        "        \n",
        "    return img, w, h\n",
        "\n",
        "\n",
        "def get_image_info(file_name, height, width, id,\n",
        "                   license=1, date_captured='', \n",
        "                   coco_url='', flickr_url='',):\n",
        "    return dict(license=license, \n",
        "                file_name=file_name,\n",
        "                coco_url=coco_url,\n",
        "                height=height,\n",
        "                width=width, \n",
        "                date_captured=date_captured,\n",
        "                flickr_url=flickr_url,\n",
        "                id=id)\n",
        "    \n",
        "\n",
        "\n",
        "def get_annot_info(kps, id, image_id, category_id=1, bbox=None, area=None,\n",
        "                   iscrowd=0, segmentation=None):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    --------------- \n",
        "    Args:\n",
        "    \n",
        "    Returns:\n",
        "    \n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"segmentation\": segmentation or [],\n",
        "        \"num_keypoints\": len(kps)//3,\n",
        "        \"area\": area if area else (bbox[2]*bbox[3]),\n",
        "        \"iscrowd\": iscrowd,\n",
        "        \"keypoints\": kps,\n",
        "        \"image_id\": image_id,\n",
        "        \"bbox\": bbox or [0, 0, 0, 0],\n",
        "        \"category_id\": category_id,\n",
        "        \"id\": id,\n",
        "    }\n",
        "\n",
        "\n",
        "def get_bbox_info(id, image_id, category_id=1, bbox=None, area=None,\n",
        "                   iscrowd=0, segmentation=None):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    --------------- \n",
        "    Args:\n",
        "    \n",
        "    Returns:\n",
        "    \n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"segmentation\": segmentation or [],\n",
        "        \"num_keypoints\": 14,\n",
        "        \"area\": area if area else (bbox[2]*bbox[3]),\n",
        "        \"iscrowd\": iscrowd,\n",
        "        \"keypoints\": [0,0,2]*14,\n",
        "        \"image_id\": image_id,\n",
        "        \"bbox\": bbox or [0, 0, 0, 0],\n",
        "        \"category_id\": category_id,\n",
        "        \"id\": id,\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dim', type=int, default=128, help='resized image shape')\n",
        "    parser.add_argument('--fold', type=int, default=0, help='fold number')\n",
        "    parser.add_argument('--is_annot', action='store_true', help=\"is there annotaions to use\")\n",
        "    parser.add_argument('--is_test', action='store_true', help=\"testing\")\n",
        "    parser.add_argument('--vip_folder', type=str, default=\"train\", help=\"VIP CUP DATA FOLDER\")\n",
        "    parser.add_argument(\"--coco_folder\", type=str, default=\"train\", help=\"folder used in coco dataset\")\n",
        "    parser.add_argument(\"--bbox_label_test\", type=str, default=\"/content/labels\", help=\"folder containing yolo labels of test person bbox\")\n",
        "    parser.add_argument(\"--base_dir\", type=str, default=\"/content/data\", help=\"base dir for vip dataset folder\")\n",
        "    parser.add_argument(\"--label\", type=str, default=\"uncover\" , help=\"uncover, cover1, cover2\")\n",
        "    parser.add_argument(\"--label2\", type=str, default=\"null\" , help=\"cover1, cover2\")\n",
        "    parser.add_argument(\"--out_dir\", type=str, default=\"/content\" , help=\"output directory\")\n",
        "    parser.add_argument('--is_aspect_ratio', action='store_true', help=\"mainatain aspect ratio. Only use dim. don't use width and height\")\n",
        "    parser.add_argument('--width', type=int, default=128, help='fold number')\n",
        "    parser.add_argument('--height', type=int, default=128, help='fold number')\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    skeleton = [(0, 1), (1, 2), (12, 2), (12, 3), (3, 4), (4, 5), (6, 7),\n",
        "                (7, 8), (8, 12), (12, 9), (9, 10), (10, 11), (12, 13)]\n",
        "    skeleton = [[x[0]+1, x[1]+1] for x in skeleton]\n",
        "    name2idx = {\n",
        "        \"Right ankle\":0,\n",
        "        \"Right knee\":1,\n",
        "        \"Right hip\":2,\n",
        "        \"Left hip\":3,\n",
        "        \"Left knee\":4,\n",
        "        \"Left ankle\":5,\n",
        "        \"Right wrist\":6,\n",
        "        \"Right elbow\":7,\n",
        "        \"Right shoulder\":8,\n",
        "        \"Left shoulder\":9,\n",
        "        \"Left elbow\":10,\n",
        "        \"Left wrist\":11,\n",
        "        \"thorax\":12,\n",
        "        \"head top\":13, \n",
        "    }\n",
        "    idx2name = {v:k for k,v in name2idx.items()}\n",
        "    names = list(idx2name.values())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_info(filepath):\n",
        "        x = filepath.split('/')\n",
        "        image_id = x[-1]\n",
        "        label    = x[-2]\n",
        "        modality = x[-3]\n",
        "        study_id = x[-4]\n",
        "        split    = x[-5]\n",
        "        return [filepath, study_id, image_id, modality, label, split]\n",
        "\n",
        "\n",
        "\n",
        "    filepaths = glob(f'{opt.base_dir}/**/*png', recursive=True)\n",
        "    filepaths.sort()\n",
        "    df = pd.DataFrame(list(map(get_info, filepaths)), columns=['image_path', 'study_id', 'image_id',\n",
        "                                                            'modality', 'label', 'split'])\n",
        "\n",
        "\n",
        "\n",
        "    df['rgb_gt_path']    = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'joints_gt_RGB.mat'))\n",
        "    df['ir_gt_path']     = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'joints_gt_IR.mat'))\n",
        "    df['rgb_align_path'] = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'align_PTr_RGB.npy'))\n",
        "    df['ir_align_path']  = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'align_PTr_IR.npy'))\n",
        "\n",
        "    df[['width', 'height']] = df.image_path.progress_apply(lambda x: list(imagesize.get(x))).tolist()\n",
        "\n",
        "\n",
        "        \n",
        "    df = df[df.split == opt.vip_folder]\n",
        "    df = df[df.modality == \"IR\"]\n",
        "\n",
        "    if opt.vip_folder == \"train\":\n",
        "        gkf = GroupKFold(n_splits=5)\n",
        "        df['fold'] = -1\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=df['study_id'])):\n",
        "            df.loc[val_idx, 'fold'] = fold\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    FOLD = opt.fold\n",
        "    if opt.vip_folder == \"train\" and opt.coco_folder == \"train\":\n",
        "        train_df = df[(df.fold!=FOLD) & (df.label==opt.label)]\n",
        "    elif opt.vip_folder == \"train\" and opt.coco_folder == \"val\":\n",
        "        train_df = df[(df.fold==FOLD) & (df.label==opt.label)]\n",
        "    else:\n",
        "        if opt.label2 == \"null\":\n",
        "            train_df = df[(df.label==opt.label)]\n",
        "        else:\n",
        "            train_df = df[(df.label==opt.label) | (df.label==opt.label2)]\n",
        "\n",
        "\n",
        "    INFO = {\n",
        "        \"description\": \"VIP CUP 2021 Dataset\",\n",
        "        \"url\": \"https://www.kaggle.com/awsaf49/ieee-vip-cup-2021-train-val-dataset\",\n",
        "        \"version\": \"0.1.0\",\n",
        "        \"year\": 2021,\n",
        "        \"contributor\": \"awsaf\",\n",
        "        \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
        "    }\n",
        "\n",
        "    LICENSES = [\n",
        "        {\n",
        "            \"id\": 1,\n",
        "            \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "            \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    CATEGORIES = [\n",
        "        {\n",
        "            'id': 1,\n",
        "            'name': 'person',\n",
        "            'supercategory': 'person',\n",
        "            \"keypoints\": names,\n",
        "            \"skeleton\": skeleton\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    coco_output = {\n",
        "        \"info\": INFO,\n",
        "        \"licenses\": LICENSES,\n",
        "        \"categories\": CATEGORIES,\n",
        "        \"images\": [],\n",
        "        \"annotations\": []\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    image_dir = f'{opt.out_dir}/coco2017/{opt.coco_folder}2017'\n",
        "    annot_dir = f'{opt.out_dir}/coco2017/annotations'\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "    os.makedirs(annot_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "    IMAGES = []\n",
        "    ANNOTATIONS = []\n",
        "    \n",
        "\n",
        "    coco_image_id=1\n",
        "    coco_annot_id=1\n",
        "    for idx in tqdm(range(train_df.shape[0])):\n",
        "        image_path = train_df.image_path.iloc[idx]\n",
        "        image_id   = train_df.image_id.iloc[idx]\n",
        "        study_id   = train_df.study_id.iloc[idx]\n",
        "        image_idx  = int(image_id.split('.')[0].split('_')[-1])-1\n",
        "        if opt.is_aspect_ratio:\n",
        "            image, width, height  = read_resize(image_path, dim=opt.dim)\n",
        "        else:\n",
        "            image, width, height  = read_resize(image_path, width=opt.width, height=opt.height, aspect_ratio=False)\n",
        "        new_height, new_width = image.shape[:2]\n",
        "        file_name = study_id + '_' + image_path.split(\"/\")[3] + \"_\" + image_path.split('/')[-1]\n",
        "\n",
        "        \n",
        "        new_image_path  = os.path.join(image_dir,file_name)\n",
        "        # writing image\n",
        "        cv2.imwrite(new_image_path, image[...,::-1])\n",
        "        # writing data\n",
        "        IMAGES.append(get_image_info(file_name, \n",
        "                                    height=int(new_height), \n",
        "                                    width=int(new_width), \n",
        "                                    id=coco_image_id,))\n",
        "        \n",
        "        if opt.is_test:\n",
        "            label_file = opt.bbox_label_test + '/' + file_name[:-3] + 'txt'\n",
        "            # SEE THIS \n",
        "            label_file = label_file.replace(f'{opt.vip_folder}', 'ieee-vip-cup-2021-train-val-dataset')\n",
        "            with open(label_file, \"r\") as f:\n",
        "                data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)[0]\n",
        "                xc, yc, w, h = data[1], data[2], data[3], data[4]\n",
        "                # using new height, new width --> REMEMBER THIS\n",
        "                xc, yc = xc*new_width, yc*new_height\n",
        "                w, h = w*new_width, h*new_height\n",
        "            \n",
        "            xmin, ymin = xc - (w/2), yc - (h/2)\n",
        "            bbox = [int(xmin), int(ymin), int(w), int(h)]\n",
        "            ANNOTATIONS.append(get_bbox_info(id=coco_annot_id, image_id=coco_image_id, category_id=1,\n",
        "                                            bbox=bbox, \n",
        "                                            area=w*h,\n",
        "                                            iscrowd=0,\n",
        "                                            segmentation=None))\n",
        "            # print(ANNOTATIONS)\n",
        "            coco_annot_id+=1\n",
        "            \n",
        "\n",
        "        if opt.is_annot:\n",
        "            kp_path = train_df.ir_gt_path.iloc[idx]\n",
        "            kps = load_kps(kp_path, \n",
        "                        width, height,\n",
        "                        new_width, new_height)\n",
        "            # kp of a image\n",
        "            kps_img = kps[image_idx]\n",
        "            # bbox from keypoints\n",
        "            xmin, ymin, xmax, ymax = np.min(kps_img[...,0]), np.min(kps_img[...,1]), np.max(kps_img[...,0]), np.max(kps_img[...,1])\n",
        "            offsetMin = int(15 * np.square((new_height*new_width) / (512*384)))\n",
        "            offsetMax = int(35 * np.square((new_height*new_width) / (512*384)))\n",
        "            xmin, ymin = int(xmin-offsetMin), int(ymin-offsetMax) # kp are too close to body so taking offset\n",
        "            xmin = max(0, xmin)\n",
        "            ymin = max(0, ymin)\n",
        "            w,h = int(xmax-xmin+offsetMin), int(ymax-ymin+offsetMax)\n",
        "            if opt.is_aspect_ratio:\n",
        "                w = min(w, opt.dim)\n",
        "                h = min(h, opt.dim)\n",
        "            else:\n",
        "                w = min(w, opt.width)\n",
        "                h = min(h, opt.height)\n",
        "            bbox = [xmin, ymin, w, h]\n",
        "\n",
        "            #============================\n",
        "            kps_img = [int(x) for x in kps_img.reshape(-1).tolist()]\n",
        "            \n",
        "            \n",
        "            \n",
        "            ANNOTATIONS.append(get_annot_info(kps=kps_img, id=coco_annot_id, image_id=coco_image_id, category_id=1,\n",
        "                                            bbox=bbox, \n",
        "                                            area=w*h,\n",
        "                                            iscrowd=0,\n",
        "                                            segmentation=None))\n",
        "            \n",
        "            coco_annot_id+=1\n",
        "        coco_image_id+=1\n",
        "        \n",
        "    #===========================\n",
        "    coco_output[\"images\"]      = IMAGES\n",
        "    coco_output[\"annotations\"] = ANNOTATIONS\n",
        "\n",
        "    # json file\n",
        "    with open(f'{annot_dir}/person_keypoints_{opt.coco_folder}2017.json', 'w') as output_json_file:\n",
        "        json.dump(coco_output, output_json_file)   \n",
        "\n",
        "\n",
        "    print(f\"Total {len(os.listdir(image_dir))} images found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evFqpZiW9jwF"
      },
      "source": [
        "!python  /content/test_coco.py --width 384 \\\n",
        "--height 512 \\\n",
        "--vip_folder \"train\" \\\n",
        "--coco_folder \"test\" \\\n",
        "--label \"cover1\" \\\n",
        "--label2 \"cover2\" \\\n",
        "--fold 0 \\\n",
        "--base_dir $vip_data_dir  \\\n",
        "--out_dir \"/content\" \\\n",
        "--is_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odOxIyZ59jcv"
      },
      "source": [
        "%%writefile /content/coco_json.py\n",
        "\n",
        "\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as scio\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import os, shutil\n",
        "from glob import glob\n",
        "tqdm.pandas()\n",
        "import json\n",
        "import datetime\n",
        "import imagesize\n",
        "from sklearn.model_selection import GroupKFold \n",
        "import scipy.io as scio\n",
        "import cv2\n",
        "\n",
        "def load_kps(kp_path, width, height, new_width, new_height):\n",
        "    gt  = scio.loadmat(kp_path)['joints_gt'] # label = if_ocluded\n",
        "    kps = gt.transpose(2, 1, 0).astype(np.float64) # => (num_image, num_limb, 3) or (None, 14, 3)\n",
        "    kps[..., 0] = (kps[...,0]-1)/width*new_width    # converting one indexing to zero indexing\n",
        "    kps[..., 1] = (kps[...,1]-1)/height*new_height\n",
        "    kps[..., 2] = 2- kps[...,2] # coco format\n",
        "    return kps.astype(np.int32)\n",
        "\n",
        "def load_image(image_path):\n",
        "    return cv2.imread(image_path)[...,::-1]\n",
        "\n",
        "\n",
        "def read_resize(file_path, dim=128, width=128, height=128, aspect_ratio=True):\n",
        "    img = load_image(file_path)\n",
        "    h, w = img.shape[:2]  # orig hw\n",
        "    if aspect_ratio:\n",
        "        r = dim / max(h, w)  # resize image to img_size\n",
        "        interp = cv2.INTER_AREA if r < 1 else cv2.INTER_LINEAR\n",
        "        if r != 1:  # always resize down, only resize up if training with augmentation\n",
        "            img = cv2.resize(img, (int(w * r), int(h * r)), interpolation=interp)\n",
        "            new_h, new_w = img.shape[:2]\n",
        "    else:\n",
        "        img = cv2.resize(img, (width,height), cv2.INTER_AREA)\n",
        "        new_w = dim; new_h = dim\n",
        "        \n",
        "    return img, w, h\n",
        "\n",
        "\n",
        "def get_image_info(file_name, height, width, id,\n",
        "                   license=1, date_captured='', \n",
        "                   coco_url='', flickr_url='',):\n",
        "    return dict(license=license, \n",
        "                file_name=file_name,\n",
        "                coco_url=coco_url,\n",
        "                height=height,\n",
        "                width=width, \n",
        "                date_captured=date_captured,\n",
        "                flickr_url=flickr_url,\n",
        "                id=id)\n",
        "    \n",
        "\n",
        "\n",
        "def get_annot_info(kps, id, image_id, category_id=1, bbox=None, area=None,\n",
        "                   iscrowd=0, segmentation=None):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    --------------- \n",
        "    Args:\n",
        "    \n",
        "    Returns:\n",
        "    \n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"segmentation\": segmentation or [],\n",
        "        \"num_keypoints\": len(kps)//3,\n",
        "        \"area\": area if area else (bbox[2]*bbox[3]),\n",
        "        \"iscrowd\": iscrowd,\n",
        "        \"keypoints\": kps,\n",
        "        \"image_id\": image_id,\n",
        "        \"bbox\": bbox or [0, 0, 0, 0],\n",
        "        \"category_id\": category_id,\n",
        "        \"id\": id,\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dim', type=int, default=128, help='resized image shape')\n",
        "    parser.add_argument('--fold', type=int, default=0, help='fold number')\n",
        "    parser.add_argument('--is_annot', action='store_true', help=\"is there annotaions to use\")\n",
        "    parser.add_argument('--vip_folder', type=str, default=\"train\", help=\"VIP CUP DATA FOLDER\")\n",
        "    parser.add_argument(\"--coco_folder\", type=str, default=\"train\", help=\"folder used in coco dataset\")\n",
        "    parser.add_argument(\"--base_dir\", type=str, default=\"/content/data\", help=\"base dir for vip dataset folder\")\n",
        "    parser.add_argument(\"--label\", type=str, default=\"uncover\" , help=\"uncover, cover1, cover2\")\n",
        "    parser.add_argument(\"--label2\", type=str, default=\"null\" , help=\"cover1, cover2\")\n",
        "    parser.add_argument(\"--out_dir\", type=str, default=\"/content\" , help=\"output directory\")\n",
        "    parser.add_argument('--is_aspect_ratio', action='store_true', help=\"mainatain aspect ratio. Only use dim. don't use width and height\")\n",
        "    parser.add_argument('--width', type=int, default=128, help='fold number')\n",
        "    parser.add_argument('--height', type=int, default=128, help='fold number')\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    skeleton = [(0, 1), (1, 2), (12, 2), (12, 3), (3, 4), (4, 5), (6, 7),\n",
        "                (7, 8), (8, 12), (12, 9), (9, 10), (10, 11), (12, 13)]\n",
        "    skeleton = [[x[0]+1, x[1]+1] for x in skeleton]\n",
        "    name2idx = {\n",
        "        \"Right ankle\":0,\n",
        "        \"Right knee\":1,\n",
        "        \"Right hip\":2,\n",
        "        \"Left hip\":3,\n",
        "        \"Left knee\":4,\n",
        "        \"Left ankle\":5,\n",
        "        \"Right wrist\":6,\n",
        "        \"Right elbow\":7,\n",
        "        \"Right shoulder\":8,\n",
        "        \"Left shoulder\":9,\n",
        "        \"Left elbow\":10,\n",
        "        \"Left wrist\":11,\n",
        "        \"thorax\":12,\n",
        "        \"head top\":13, \n",
        "    }\n",
        "    idx2name = {v:k for k,v in name2idx.items()}\n",
        "    names = list(idx2name.values())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_info(filepath):\n",
        "        x = filepath.split('/')\n",
        "        image_id = x[-1]\n",
        "        label    = x[-2]\n",
        "        modality = x[-3]\n",
        "        study_id = x[-4]\n",
        "        split    = x[-5]\n",
        "        return [filepath, study_id, image_id, modality, label, split]\n",
        "\n",
        "\n",
        "\n",
        "    filepaths = glob(f'{opt.base_dir}/**/*png', recursive=True)\n",
        "    filepaths.sort()\n",
        "    df = pd.DataFrame(list(map(get_info, filepaths)), columns=['image_path', 'study_id', 'image_id',\n",
        "                                                            'modality', 'label', 'split'])\n",
        "\n",
        "\n",
        "\n",
        "    df['rgb_gt_path']    = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'joints_gt_RGB.mat'))\n",
        "    df['ir_gt_path']     = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'joints_gt_IR.mat'))\n",
        "    df['rgb_align_path'] = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'align_PTr_RGB.npy'))\n",
        "    df['ir_align_path']  = df.image_path.map(lambda x: os.path.join(x.rsplit('/', 3)[0], 'align_PTr_IR.npy'))\n",
        "\n",
        "    df[['width', 'height']] = df.image_path.progress_apply(lambda x: list(imagesize.get(x))).tolist()\n",
        "\n",
        "\n",
        "        \n",
        "    df = df[df.split == opt.vip_folder]\n",
        "    df = df[df.modality == \"IR\"]\n",
        "\n",
        "    if opt.vip_folder == \"train\":\n",
        "        gkf = GroupKFold(n_splits=5)\n",
        "        df['fold'] = -1\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=df['study_id'])):\n",
        "            df.loc[val_idx, 'fold'] = fold\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    FOLD = opt.fold\n",
        "    if opt.vip_folder == \"train\" and opt.coco_folder == \"train\":\n",
        "        train_df = df[(df.fold!=FOLD) & (df.label==opt.label)]\n",
        "    elif opt.vip_folder == \"train\" and opt.coco_folder == \"val\":\n",
        "        train_df = df[(df.fold==FOLD) & (df.label==opt.label)]\n",
        "    else:\n",
        "        if opt.label2 == \"null\":\n",
        "            train_df = df[(df.label==opt.label)]\n",
        "        else:\n",
        "            train_df = df[(df.label==opt.label) | (df.label==opt.label2)]\n",
        "\n",
        "\n",
        "    INFO = {\n",
        "        \"description\": \"VIP CUP 2021 Dataset\",\n",
        "        \"url\": \"https://www.kaggle.com/awsaf49/ieee-vip-cup-2021-train-val-dataset\",\n",
        "        \"version\": \"0.1.0\",\n",
        "        \"year\": 2021,\n",
        "        \"contributor\": \"awsaf\",\n",
        "        \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
        "    }\n",
        "\n",
        "    LICENSES = [\n",
        "        {\n",
        "            \"id\": 1,\n",
        "            \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "            \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    CATEGORIES = [\n",
        "        {\n",
        "            'id': 1,\n",
        "            'name': 'person',\n",
        "            'supercategory': 'person',\n",
        "            \"keypoints\": names,\n",
        "            \"skeleton\": skeleton\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    coco_output = {\n",
        "        \"info\": INFO,\n",
        "        \"licenses\": LICENSES,\n",
        "        \"categories\": CATEGORIES,\n",
        "        \"images\": [],\n",
        "        \"annotations\": []\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    image_dir = f'{opt.out_dir}/coco2017/{opt.coco_folder}2017'\n",
        "    annot_dir = f'{opt.out_dir}/coco2017/annotations'\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "    os.makedirs(annot_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "    IMAGES = []\n",
        "    ANNOTATIONS = []\n",
        "    \n",
        "\n",
        "    coco_image_id=1\n",
        "    coco_annot_id=1\n",
        "    for idx in tqdm(range(train_df.shape[0])):\n",
        "        image_path = train_df.image_path.iloc[idx]\n",
        "        image_id   = train_df.image_id.iloc[idx]\n",
        "        study_id   = train_df.study_id.iloc[idx]\n",
        "        image_idx  = int(image_id.split('.')[0].split('_')[-1])-1\n",
        "        if opt.is_aspect_ratio:\n",
        "            image, width, height  = read_resize(image_path, dim=opt.dim)\n",
        "        else:\n",
        "            image, width, height  = read_resize(image_path, width=opt.width, height=opt.height, aspect_ratio=False)\n",
        "        new_height, new_width = image.shape[:2]\n",
        "        file_name = study_id + '_' + image_path.split(\"/\")[3] + \"_\" + image_path.split('/')[-1]\n",
        "        new_image_path  = os.path.join(image_dir,file_name)\n",
        "        # writing image\n",
        "        cv2.imwrite(new_image_path, image[...,::-1])\n",
        "        # writing data\n",
        "        IMAGES.append(get_image_info(file_name, \n",
        "                                    height=int(new_height), \n",
        "                                    width=int(new_width), \n",
        "                                    id=coco_image_id,))\n",
        "\n",
        "        if opt.is_annot:\n",
        "            kp_path = train_df.ir_gt_path.iloc[idx]\n",
        "            kps = load_kps(kp_path, \n",
        "                        width, height,\n",
        "                        new_width, new_height)\n",
        "            # kp of a image\n",
        "            kps_img = kps[image_idx]\n",
        "            # bbox from keypoints\n",
        "            xmin, ymin, xmax, ymax = np.min(kps_img[...,0]), np.min(kps_img[...,1]), np.max(kps_img[...,0]), np.max(kps_img[...,1])\n",
        "            offsetMin = int(15 * np.square((new_height*new_width) / (512*384)))\n",
        "            offsetMax = int(35 * np.square((new_height*new_width) / (512*384)))\n",
        "            xmin, ymin = int(xmin-offsetMin), int(ymin-offsetMax) # kp are too close to body so taking offset\n",
        "            xmin = max(0, xmin)\n",
        "            ymin = max(0, ymin)\n",
        "            w,h = int(xmax-xmin+offsetMin), int(ymax-ymin+offsetMax)\n",
        "            if opt.is_aspect_ratio:\n",
        "                w = min(w, opt.dim)\n",
        "                h = min(h, opt.dim)\n",
        "            else:\n",
        "                w = min(w, opt.width)\n",
        "                h = min(h, opt.height)\n",
        "            bbox = [xmin, ymin, w, h]\n",
        "\n",
        "            #============================\n",
        "            kps_img = [int(x) for x in kps_img.reshape(-1).tolist()]\n",
        "            \n",
        "            \n",
        "            \n",
        "            ANNOTATIONS.append(get_annot_info(kps=kps_img, id=coco_annot_id, image_id=coco_image_id, category_id=1,\n",
        "                                            bbox=bbox, \n",
        "                                            area=w*h,\n",
        "                                            iscrowd=0,\n",
        "                                            segmentation=None))\n",
        "            \n",
        "            coco_annot_id+=1\n",
        "        coco_image_id+=1\n",
        "        \n",
        "    #===========================\n",
        "    coco_output[\"images\"]      = IMAGES\n",
        "    coco_output[\"annotations\"] = ANNOTATIONS\n",
        "\n",
        "    # json file\n",
        "    with open(f'{annot_dir}/person_keypoints_{opt.coco_folder}2017.json', 'w') as output_json_file:\n",
        "        json.dump(coco_output, output_json_file)   \n",
        "\n",
        "\n",
        "    print(f\"Total {len(os.listdir(image_dir))} images found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJbStgyD98XM"
      },
      "source": [
        "!python /content/coco_json.py --fold -1 \\\n",
        "--is_annot \\\n",
        "--vip_folder \"train\" \\\n",
        "--coco_folder \"train\" \\\n",
        "--base_dir $vip_transformed_data_dir \\\n",
        "--label \"uncover\" \\\n",
        "--out_dir \"/content\" \\\n",
        "--width 384 \\\n",
        "--height 512 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vrowOHx-CrP"
      },
      "source": [
        "!python /content/coco_json.py --width 384 \\\n",
        "--height 512 \\\n",
        "--is_annot \\\n",
        "--vip_folder \"valid\" \\\n",
        "--coco_folder \"val\" \\\n",
        "--label \"cover1\" \\\n",
        "--label2 \"cover2\" \\\n",
        "--fold 0 \\\n",
        "--base_dir $vip_data_dir  \\\n",
        "--out_dir \"/content\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVT64RPH-Iuk"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "\n",
        "width = 384\n",
        "height = 512\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_image_info(file_name, height, width, id,\n",
        "                   license=1, date_captured='', \n",
        "                   coco_url='', flickr_url='',):\n",
        "    return dict(license=license, \n",
        "                file_name=file_name,\n",
        "                coco_url=coco_url,\n",
        "                height=height,\n",
        "                width=width, \n",
        "                date_captured=date_captured,\n",
        "                flickr_url=flickr_url,\n",
        "                id=id)\n",
        "    \n",
        "\n",
        "def get_annot_info(kps, id, image_id, category_id=1, bbox=None, area=None,\n",
        "                   iscrowd=0, segmentation=None):\n",
        "    return {\n",
        "        \"segmentation\": segmentation or [],\n",
        "        \"num_keypoints\": len(kps)//3,\n",
        "        \"area\": area if area else (bbox[2]*bbox[3]),\n",
        "        \"iscrowd\": iscrowd,\n",
        "        \"keypoints\": kps,\n",
        "        \"image_id\": image_id,\n",
        "        \"bbox\": bbox or [0, 0, 0, 0],\n",
        "        \"category_id\": category_id,\n",
        "        \"id\": id,\n",
        "    }\n",
        "\n",
        "IMAGES = []\n",
        "ANNOTATIONS = []\n",
        "with open(\"/content/coco2017/annotations/person_keypoints_train2017.json\") as f: \n",
        "    annots = json.load(f)\n",
        "\n",
        "folder = \"/content/coco2017/test2017\"\n",
        "\n",
        "result_df = pd.read_csv(pseudo_df)\n",
        "\n",
        "IMAGES = annots['images']\n",
        "ANNOTATIONS = annots['annotations']\n",
        "\n",
        "coco_image_id = len(IMAGES) + 1\n",
        "coco_annot_id = len(ANNOTATIONS) + 1\n",
        "\n",
        "image_paths = os.listdir(folder)\n",
        "image_paths.sort()\n",
        "\n",
        "sz = len(image_paths)\n",
        "for idx in range(sz):\n",
        "    file_name = image_paths[idx]\n",
        "    image_path = \"/content/coco2017/test2017/\" + file_name\n",
        "    new_image_path = \"/content/coco2017/train2017/\" + file_name\n",
        "    image = cv2.imread(image_path)[...,::-1]\n",
        "    image = cv2.resize(image, (width,height), cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "    IMAGES.append(get_image_info(file_name, \n",
        "                    height=int(height), \n",
        "                    width=int(width), \n",
        "                    id=coco_image_id,))\n",
        "    \n",
        "\n",
        "\n",
        "    df_search_name = file_name.replace(\"train_\", \"\")\n",
        "    kps = ast.literal_eval(result_df[result_df.filename == df_search_name].kps.values[0])\n",
        "    kps = np.array(kps)\n",
        "    kps[:, 0] = kps[:, 0] * (width/120)\n",
        "    kps[:, 1] = kps[:, 1] * (height/160)\n",
        "    kps = kps.astype(np.int32)\n",
        "    kps = kps.tolist()\n",
        "    kpts = []\n",
        "    for kp in kps:\n",
        "        kpts += kp\n",
        "\n",
        "    label_file = \"/content/labels\" + '/' + file_name[:-3] + 'txt'\n",
        "    # SEE THIS \n",
        "    label_file = label_file.replace('train', 'ieee-vip-cup-2021-train-val-dataset')\n",
        "\n",
        "    with open(label_file, \"r\") as f:\n",
        "        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)[0]\n",
        "        xc, yc, w, h = data[1], data[2], data[3], data[4]\n",
        "        # using new height, new width --> REMEMBER THIS\n",
        "        xc, yc = xc*width, yc*height\n",
        "        w, h = w*width, h*height\n",
        "    xmin, ymin = xc - (w/2), yc - (h/2)\n",
        "    bbox = [int(xmin), int(ymin), int(w), int(h)]\n",
        "\n",
        "    ANNOTATIONS.append(get_annot_info(kps=kpts, id=coco_annot_id, image_id=coco_image_id, category_id=1,\n",
        "                                bbox=bbox, \n",
        "                                area=int(w*h),\n",
        "                                iscrowd=0,\n",
        "                                segmentation=None))\n",
        "    \n",
        "    cv2.imwrite(new_image_path, image[...,::-1])\n",
        "    coco_image_id += 1\n",
        "    coco_annot_id+=1\n",
        "\n",
        "\n",
        "skeleton = [(0, 1), (1, 2), (12, 2), (12, 3), (3, 4), (4, 5), (6, 7),\n",
        "            (7, 8), (8, 12), (12, 9), (9, 10), (10, 11), (12, 13)]\n",
        "skeleton = [[x[0]+1, x[1]+1] for x in skeleton]\n",
        "name2idx = {\n",
        "    \"Right ankle\":0,\n",
        "    \"Right knee\":1,\n",
        "    \"Right hip\":2,\n",
        "    \"Left hip\":3,\n",
        "    \"Left knee\":4,\n",
        "    \"Left ankle\":5,\n",
        "    \"Right wrist\":6,\n",
        "    \"Right elbow\":7,\n",
        "    \"Right shoulder\":8,\n",
        "    \"Left shoulder\":9,\n",
        "    \"Left elbow\":10,\n",
        "    \"Left wrist\":11,\n",
        "    \"thorax\":12,\n",
        "    \"head top\":13, \n",
        "}\n",
        "idx2name = {v:k for k,v in name2idx.items()}\n",
        "names = list(idx2name.values())\n",
        "\n",
        "\n",
        "INFO = {\n",
        "    \"description\": \"VIP CUP 2021 Dataset\",\n",
        "    \"url\": \"https://www.kaggle.com/awsaf49/ieee-vip-cup-2021-train-val-dataset\",\n",
        "    \"version\": \"0.1.0\",\n",
        "    \"year\": 2021,\n",
        "    \"contributor\": \"awsaf\",\n",
        "    \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
        "}\n",
        "\n",
        "LICENSES = [\n",
        "    {\n",
        "        \"id\": 1,\n",
        "        \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "        \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "    }\n",
        "]\n",
        "\n",
        "CATEGORIES = [\n",
        "    {\n",
        "        'id': 1,\n",
        "        'name': 'person',\n",
        "        'supercategory': 'person',\n",
        "        \"keypoints\": names,\n",
        "        \"skeleton\": skeleton\n",
        "    },\n",
        "]\n",
        "\n",
        "coco_output = {\n",
        "    \"info\": INFO,\n",
        "    \"licenses\": LICENSES,\n",
        "    \"categories\": CATEGORIES,\n",
        "    \"images\": [],\n",
        "    \"annotations\": []\n",
        "}\n",
        "\n",
        "\n",
        "coco_output[\"images\"]      = IMAGES\n",
        "coco_output[\"annotations\"] = ANNOTATIONS\n",
        "\n",
        "with open(f'/content/coco2017/annotations/person_keypoints_train2017.json', 'w') as output_json_file:\n",
        "    json.dump(coco_output, output_json_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LADX-tmz-aAl"
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/coco2017/test2017\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_mLZw5J-i5C"
      },
      "source": [
        "# Model & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRp2eCGu-dX_"
      },
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUpGgWF8-odO"
      },
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/{11.2}/{1.9.0}/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx0z7zhN-oau"
      },
      "source": [
        "!git clone https://Md-Jahin-Alam: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@github.com/Najib-Haq/MMPose.git mmpose "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq0Fj3hX-oXD"
      },
      "source": [
        "%cd mmpose/mmpose_folder \n",
        "!pip install -r requirements.txt \n",
        "!python setup.py develop "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELvTBJYM-oUZ"
      },
      "source": [
        "import shutil\n",
        "shutil.copytree(\"/content/coco2017\", \"/content/mmpose/mmpose_folder/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xla0hqCY-oRo"
      },
      "source": [
        "!python tools/train.py \"custom_configs/coco_configs/litehrnet_30_coco_384x288.py\" \\\n",
        "--batch $BATCH_SIZE \\\n",
        "--work-dir $work_dir \\\n",
        "--load-from $weight_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRrqdJX4-oO3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkMRPufV-oMH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}